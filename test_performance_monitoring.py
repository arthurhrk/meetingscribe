#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Teste do Sistema de Monitoramento de Performance
Verifica se todas as funcionalidades de performance estÃ£o funcionando
"""

import time
import json
import sys
from pathlib import Path

# Adicionar o diretÃ³rio raiz ao path
sys.path.insert(0, str(Path(__file__).parent))

try:
    from src.core.performance_monitor import (
        get_performance_monitor, 
        TranscriptionMetrics, 
        PerformanceTimer
    )
    from src.core.raycast_metrics_cli import RaycastMetricsCLI
    print("âœ… Imports do monitoramento de performance OK")
except ImportError as e:
    print(f"âŒ Erro ao importar mÃ³dulos de performance: {e}")
    sys.exit(1)

def test_performance_monitor():
    """Testa o monitor de performance"""
    print("\nğŸ” Testando Performance Monitor...")
    
    try:
        # Inicializar monitor
        monitor = get_performance_monitor()
        print("âœ… Monitor inicializado")
        
        # Testar adiÃ§Ã£o de mÃ©trica
        monitor.add_metric("test_metric", 42.0, "test_unit", "test_category")
        print("âœ… MÃ©trica adicionada")
        
        # Testar mÃ©tricas de transcriÃ§Ã£o
        test_metrics = TranscriptionMetrics(
            duration=10.5,
            audio_length=10.5,
            model_size="base",
            chunks_count=1,
            processing_time=2.3,
            cache_hits=1,
            memory_used=150.0,
            gpu_used=False,
            success=True
        )
        
        monitor.add_transcription_metrics(test_metrics)
        print("âœ… MÃ©tricas de transcriÃ§Ã£o adicionadas")
        
        # Testar obtenÃ§Ã£o de mÃ©tricas
        raycast_metrics = monitor.get_metrics_for_raycast()
        print("âœ… MÃ©tricas para Raycast obtidas")
        print(f"   Sistema: {raycast_metrics['system']['status']}")
        print(f"   Cache: {raycast_metrics['cache']['status']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste do monitor: {e}")
        return False

def test_performance_timer():
    """Testa o timer de performance"""
    print("\nâ±ï¸ Testando Performance Timer...")
    
    try:
        # Testar context manager
        with PerformanceTimer("test_operation", "test"):
            time.sleep(0.1)  # Simular operaÃ§Ã£o
        
        print("âœ… Performance Timer funcionando")
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste do timer: {e}")
        return False

def test_raycast_cli():
    """Testa a interface CLI para Raycast"""
    print("\nğŸ“Š Testando Raycast CLI...")
    
    try:
        cli = RaycastMetricsCLI()
        
        # Testar status do sistema
        status = cli.get_system_status()
        print("âœ… Status do sistema obtido")
        print(f"   Health: {status.get('health', 'unknown')}")
        
        # Testar dashboard
        dashboard = cli.get_dashboard_data()
        print("âœ… Dashboard obtido")
        print(f"   Status: {dashboard.get('status', 'unknown')}")
        
        # Testar cache
        cache_status = cli.get_cache_status()
        print("âœ… Status do cache obtido")
        print(f"   Status: {cache_status.get('status', 'unknown')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste do CLI: {e}")
        return False

def test_cli_integration():
    """Testa integraÃ§Ã£o com main.py via CLI"""
    print("\nğŸ”— Testando IntegraÃ§Ã£o CLI...")
    
    try:
        import subprocess
        
        # Testar comando de status
        result = subprocess.run([
            sys.executable, "main.py", "--performance", "status"
        ], capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            data = json.loads(result.stdout)
            print("âœ… Comando CLI --performance status funcionando")
            print(f"   Health: {data.get('health', 'unknown')}")
        else:
            print(f"âŒ Comando CLI falhou: {result.stderr}")
            return False
        
        return True
        
    except subprocess.TimeoutExpired:
        print("âŒ Timeout no comando CLI")
        return False
    except Exception as e:
        print(f"âŒ Erro no teste CLI: {e}")
        return False

def test_metric_persistence():
    """Testa persistÃªncia de mÃ©tricas"""
    print("\nğŸ’¾ Testando PersistÃªncia de MÃ©tricas...")
    
    try:
        monitor = get_performance_monitor()
        
        # Adicionar algumas mÃ©tricas
        for i in range(5):
            monitor.add_metric(f"test_persist_{i}", float(i), "count", "test")
        
        # ForÃ§ar persistÃªncia
        monitor._persist_metrics()
        print("âœ… MÃ©tricas persistidas")
        
        # Verificar arquivo
        metrics_file = Path("storage/metrics/performance_metrics.json")
        if metrics_file.exists():
            print("âœ… Arquivo de mÃ©tricas existe")
            
            with open(metrics_file, 'r') as f:
                data = json.load(f)
            
            if data.get('metrics'):
                print(f"âœ… {len(data['metrics'])} mÃ©tricas salvas")
            else:
                print("âŒ Nenhuma mÃ©trica encontrada no arquivo")
                return False
        else:
            print("âŒ Arquivo de mÃ©tricas nÃ£o encontrado")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste de persistÃªncia: {e}")
        return False

def run_performance_benchmark():
    """Executa benchmark bÃ¡sico do sistema"""
    print("\nğŸš€ Executando Benchmark de Performance...")
    
    try:
        monitor = get_performance_monitor()
        
        # Simular vÃ¡rias operaÃ§Ãµes
        operations = [
            ("cpu_intensive", lambda: sum(i**2 for i in range(10000))),
            ("memory_allocation", lambda: [i for i in range(100000)]),
            ("file_operation", lambda: Path("test_file.tmp").write_text("test")),
        ]
        
        results = []
        
        for name, operation in operations:
            with PerformanceTimer(name, "benchmark") as timer:
                operation()
                time.sleep(0.01)  # Pequena pausa
            
            # A mÃ©trica foi automaticamente adicionada pelo timer
            results.append(name)
        
        # Limpar arquivo temporÃ¡rio
        test_file = Path("test_file.tmp")
        if test_file.exists():
            test_file.unlink()
        
        print(f"âœ… Benchmark concluÃ­do: {len(results)} operaÃ§Ãµes")
        
        # Obter resumo das mÃ©tricas
        metrics = monitor.get_metrics_for_raycast()
        print(f"âœ… MÃ©tricas coletadas: {len(metrics.get('recent_metrics', []))} recentes")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no benchmark: {e}")
        return False

def main():
    """FunÃ§Ã£o principal de teste"""
    print("ğŸ§ª === Teste do Sistema de Monitoramento de Performance ===")
    print(f"ğŸ“ DiretÃ³rio: {Path.cwd()}")
    
    tests = [
        ("Performance Monitor", test_performance_monitor),
        ("Performance Timer", test_performance_timer),
        ("Raycast CLI", test_raycast_cli),
        ("CLI Integration", test_cli_integration),
        ("Metric Persistence", test_metric_persistence),
        ("Performance Benchmark", run_performance_benchmark),
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        print(f"\n{'='*50}")
        print(f"ğŸ§ª TESTE: {test_name}")
        print('='*50)
        
        try:
            if test_func():
                print(f"âœ… {test_name}: PASSOU")
                passed += 1
            else:
                print(f"âŒ {test_name}: FALHOU")
                failed += 1
        except Exception as e:
            print(f"ğŸ’¥ {test_name}: ERRO - {e}")
            failed += 1
    
    print(f"\n{'='*50}")
    print("ğŸ“Š RESUMO DOS TESTES")
    print('='*50)
    print(f"âœ… Passaram: {passed}")
    print(f"âŒ Falharam: {failed}")
    print(f"ğŸ“Š Total: {passed + failed}")
    
    if failed == 0:
        print("\nğŸ‰ TODOS OS TESTES PASSARAM!")
        print("ğŸš€ Sistema de monitoramento de performance estÃ¡ funcionando!")
        return 0
    else:
        print(f"\nâš ï¸ {failed} teste(s) falharam")
        print("ğŸ”§ Verifique os erros acima e corrija os problemas")
        return 1

if __name__ == "__main__":
    sys.exit(main())